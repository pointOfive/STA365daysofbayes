{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3c5851",
   "metadata": {},
   "source": [
    "# PyMC and Universal Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c33c2",
   "metadata": {},
   "source": [
    "## Part A: `import pymc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119069bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3f267",
   "metadata": {},
   "source": [
    "- [Introductory Overview of PyMC](https://www.pymc.io/projects/docs/en/latest/learn/core_notebooks/pymc_overview.html)\n",
    "- [Example Gallary](https://www.pymc.io/projects/examples/en/latest/gallery.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running on PyMC v{pymc.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0383bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "true_theta, true_tau = 0,1\n",
    "data_generating_mechanism = \\\n",
    "stats.norm(loc=true_theta, scale=true_tau**(-0.5))\n",
    "\n",
    "x = data_generating_mechanism.rvs(size=n)\n",
    "plt.hist(x, density=True)\n",
    "x_grid = np.linspace(-5*true_tau**(-0.5),5*true_tau**(-0.5),1000)\n",
    "plt.plot(x_grid,data_generating_mechanism.pdf(x_grid));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c46236",
   "metadata": {},
   "outputs": [],
   "source": [
    "conjugate_normal_gamma = pymc.Model()\n",
    "\n",
    "with conjugate_normal_gamma:\n",
    "\n",
    "    # Priors for unknown model parameters\n",
    "    \n",
    "    theta0 = 0  # prior belief regarding true_theta\n",
    "    theta_prior_n = 1  # strength of prior belief as units of data\n",
    "    # theta_prior_n = tau0/true_tau\n",
    "    tau0 = theta_prior_n*true_tau  \n",
    "    theta = pymc.Normal(\"theta\", mu=theta0, sigma=tau0**(-0.5))\n",
    "    # Compared to scipy.stats\n",
    "    # loc -> mu\n",
    "    # scale -> sigma but you can also use tau as below...\n",
    "    \n",
    "    tau_SS_prior = 1  # prior belief regarding true_sum_of_squares\n",
    "    tau_prior_n = 1  # strength of prior belief as units of data\n",
    "    tau = pymc.Gamma(\"tau\", alpha=tau_prior_n/2, \n",
    "                            beta=tau_SS_prior/2)\n",
    "    # https://en.wikipedia.org/wiki/Gamma_distribution\n",
    "    # pymc.Gamma?\n",
    "    # Now it's **rate** (beta) NOT scale\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    x_obs = pymc.Normal(\"x_obs\", mu=theta, tau=tau, observed=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc.model_to_graphviz(conjugate_normal_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcd8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10000\n",
    "with conjugate_normal_gamma:\n",
    "    # draw m posterior samples\n",
    "    idata = pymc.sample(draws=m, chains=2, tune=100)\n",
    "    # arviz.InferenceData object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84454f",
   "metadata": {},
   "source": [
    "## `idata` and `arviz as az`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f297417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.posterior['theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb21172",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.posterior['tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = idata.posterior['theta'].values#.shape\n",
    "tau = idata.posterior['tau'].values#.shape\n",
    "\n",
    "fig,ax = plt.subplots(1, 4, figsize=(14,3));ax[0].set_title(\"$\\\\theta$ Burn-In\"); ax[1].set_title(\"$\\\\tau$ Burn-In\"); ax[2].set_title(\"$\\\\theta$ Converged Markov Chain\\nStationary Distribution Samples\"); ax[3].set_title(\"$\\\\tau$ Converged Markov Chain\\nStationary Distribution Samples\")\n",
    "\n",
    "# pymc.sample(draws=1000, chains=2, tune=100)\n",
    "# used 100 samples per chain to \"tune\" and these were\n",
    "# automatically discarded so `burn` is likely not needed\n",
    "burn = 20\n",
    "demo = 120\n",
    "C = 2\n",
    "for c in range(C):\n",
    "    ax[0].plot(theta[c,:burn], label=\"$\\\\theta$ Chain \"+str(c))\n",
    "    ax[1].plot(tau[c,:burn], label=\"$\\\\tau$ Chain \"+str(c))\n",
    "    ax[2].plot(np.arange(burn, demo, dtype=int), theta[c,burn:demo], label=\"$\\\\theta$ Chain \"+str(c))\n",
    "    ax[3].plot(np.arange(burn, demo, dtype=int), tau[c,burn:demo], label=\"$\\\\tau$ Chain \"+str(c))\n",
    "ax[0].legend(); ax[1].legend(); ax[2].legend(); ax[3].legend();  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 3, figsize=(16,4))\n",
    "ax[0].set_title(\"Marginal distribution of $\\\\theta$ (without burn-in)\\nof (joint posterior) stationary distribution\")\n",
    "ax[1].set_title(\"Marginal distribution of $\\\\tau$ (without burn-in)\\nof (joint posterior) stationary distribution\")\n",
    "ax[2].set_title(\"Joint (posterior) stationary distribution\\n(without burn-in)\")\n",
    "\n",
    "ax[0].hist(theta[0,burn:])\n",
    "ax[1].hist(tau[0,burn:])\n",
    "ax[2].plot(theta[0,burn:], tau[0,burn:], '.', alpha=0.1);\n",
    "demo = 3*burn\n",
    "ax[2].plot(theta[0,burn:demo], tau[0,burn:demo]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f98c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, combined=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6092a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "with conjugate_normal_gamma:\n",
    "    # draw m posterior samples\n",
    "    idata = pymc.sample(draws=m, chains=2, tune=100)\n",
    "    # arviz.InferenceData object\n",
    "\n",
    "theta = idata.posterior['theta'].values#.shape\n",
    "tau = idata.posterior['tau'].values#.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the messages below don't show\n",
    "\"\"\"Auto-assigning NUTS sampler...\n",
    "   Initializing NUTS using jitter+adapt_diag...\n",
    "   Multiprocess sampling (2 chains in 4 jobs)\n",
    "   NUTS: [theta, tau] \"\"\"\n",
    "# You can see this information by turning on logging\n",
    "import logging # dir(logging) for available functionality\n",
    "_log = logging.getLogger(\"pymc\")\n",
    "#_log.setLevel(logging.NOTSET) # 0\n",
    "_log.setLevel(logging.INFO) # 20\n",
    "#_log.setLevel(logging.WARNING) # 30\n",
    "#_log.setLevel(logging.ERROR) # 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(idata, var_names=[\"theta\", \"tau\"], \n",
    "               combined=False, hdi_prob=0.95, r_hat=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac953bc",
   "metadata": {},
   "source": [
    "## Part B: Posterior inference and diagnostics<br><sub>with `az.summary`</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72989d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, round_to=5)#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10895b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta.ravel().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7766cf2",
   "metadata": {},
   "source": [
    "### `mean` and `sd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4065274",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_to=5\n",
    "theta.ravel().mean().round(round_to), tau.ravel().mean().round(round_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta.ravel().std().round(round_to), tau.ravel().std().round(round_to)\n",
    "theta.ravel().std(ddof=1).round(round_to), tau.ravel().std(ddof=1).round(round_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21887c",
   "metadata": {},
   "source": [
    "### `hdi_3%` and `hdi_97%`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeef889",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, round_to=5)#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549fa647",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(theta,[0.05,0.95]).round(round_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d8d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(theta,[0.025,0.975]).round(round_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(theta,[0.03,0.97]).round(round_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdi_3% and hdi_97% is something like\n",
    "# move interval up or down until the smallest interval is found\n",
    "np.quantile(theta,[0.02,0.96]).round(round_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d498c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so trying to get a bit closer for tau it's someting like\n",
    "np.quantile(tau,[0.022,0.9622]).round(round_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80be109",
   "metadata": {},
   "source": [
    "### To consider `mcse_mean` and `mcse_sd`...\n",
    "\n",
    "- [...moments of moments and first order Taylor series approximation](https://mc-stan.org/posterior/reference/mcse_sd.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae25b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, round_to=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, round_to=5)['sd']['theta']/\\\n",
    "az.summary(idata, round_to=5)['ess_bulk']['theta']**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525402ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, round_to=5)['sd']['tau']/\\\n",
    "(az.summary(idata, round_to=5)['ess_bulk']['tau']+0)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "((theta.ravel()-theta.ravel().mean())**2).var()/\\\n",
    "az.summary(idata, round_to=5)['ess_bulk']['theta']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac240b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this estimates y which is the variance\n",
    "((theta.ravel()-theta.ravel().mean())**2).mean()\n",
    "theta.ravel().var()\n",
    "# square root of this estimates standard deviation\n",
    "# s = sqrt(y)\n",
    "\n",
    "# this estimates variance of y above estimator\n",
    "((theta.ravel()-theta.ravel().mean())**2).var()/\\\n",
    "az.summary(idata, round_to=5)['ess_bulk']['theta']\n",
    "\n",
    "# by the delta method \n",
    "# https://stats.stackexchange.com/questions/491845/how-is-delta-method-used-here-in-approximating-the-square-root-of-a-normal-rando\n",
    "# var(S) = (1/sqrt(E[Y]))**2 * Var(Y)\n",
    "\n",
    "((1/theta.ravel().var())*\\\n",
    " ((theta.ravel()-theta.ravel().mean())**2).var()/\\\n",
    " az.summary(idata, round_to=15)['ess_bulk']['theta'])**0.5\n",
    "\n",
    "# So it's not quite right...but then again it's maybe not exactly\n",
    "# https://mc-stan.org/posterior/reference/mcse_sd.html\n",
    "# \"Compute the Monte Carlo standard error for the \n",
    "#  standard deviation (SD) of a single variable \n",
    "#  without assuming normality using moments of moments \n",
    "#  and first order Taylor series approximation \n",
    "#  (Kenney and Keeping, 1951, p. 141).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "((1/tau.ravel().var())*\\\n",
    " ((tau.ravel()-tau.ravel().mean())**2).var()/\\\n",
    " az.summary(idata, round_to=15)['ess_bulk']['tau'])**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, round_to=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bb7fd9",
   "metadata": {},
   "source": [
    "### We must first consider `bulk_tail` and `ess_tail`...\n",
    "\n",
    "- [bulk_tail](https://mc-stan.org/posterior/reference/ess_bulk.html)\n",
    "- [ess_tail](https://mc-stan.org/posterior/reference/ess_tail.html)\n",
    "\n",
    "#### Effective sample size\n",
    "\n",
    "$$n_{\\text{eff}} = \\frac{m}{\\sum_{k=-\\infty}^\\infty\\rho_k} = \\frac{m}{1+2\\sum_{k=1}^\\infty\\rho_k} \\quad \\text{ for order $k$ autocorrelations } \\quad \\rho_k $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd44cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_in_tail = \\\n",
    "(theta<=np.quantile(theta.ravel(),0.05))#+\\\n",
    "(theta>=np.quantile(theta.ravel(),0.95))\n",
    "print(theta_in_tail.sum()/(2*m))\n",
    "theta_in_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bcb63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "K = 30\n",
    "autocorrelations = np.ones((2,int(m/2)))\n",
    "for c in range(C):\n",
    "    for t_plus_k in range(1, int(m/2)):\n",
    "        autocorrelations[c,t_plus_k] = \\\n",
    "        np.corrcoef(theta_in_tail[c,:-t_plus_k], \n",
    "                    theta_in_tail[c,t_plus_k:])[0,1]\n",
    "\n",
    "for c in range(C):\n",
    "    plt.plot(autocorrelations[c,:K], label=\"Chain \"+str(c)) \n",
    "\n",
    "# effective sample size\n",
    "approximation_stops=[5,4]\n",
    "approximation_stops,\n",
    "m / (1 + 2*autocorrelations[0,1:approximation_stops[0]].sum())+\\\n",
    "m / (1 + 2*autocorrelations[1,1:approximation_stops[1]].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelations[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_in_tail = \\\n",
    "(tau<=np.quantile(tau.ravel(),0.05))+\\\n",
    "(tau>=np.quantile(tau.ravel(),0.95))\n",
    "print(tau_in_tail.sum()/(2*m))\n",
    "tau_in_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2fc711",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "K = 30\n",
    "autocorrelations = np.ones((2,m-1))\n",
    "for c in range(C):\n",
    "    for t_plus_k in range(1, int(m/2)):\n",
    "        autocorrelations[c,t_plus_k] = \\\n",
    "        np.corrcoef(tau_in_tail[c,:-t_plus_k], \n",
    "                    tau_in_tail[c,t_plus_k:])[0,1]\n",
    "        \n",
    "for c in range(C):\n",
    "    plt.plot(autocorrelations[c,:K], label=\"Chain \"+str(c)) \n",
    "\n",
    "# effective sample size\n",
    "approximation_stops=[8,6]\n",
    "approximation_stops,\n",
    "m / (1 + 2*autocorrelations[0,1:approximation_stops[0]].sum())+\\\n",
    "m / (1 + 2*autocorrelations[1,1:approximation_stops[1]].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea74649",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelations[:,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb48e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, round_to=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7fbe71",
   "metadata": {},
   "source": [
    "#### Reminder \n",
    "\n",
    "- [bulk_tail](https://mc-stan.org/posterior/reference/ess_bulk.html)\n",
    "- [ess_tail](https://mc-stan.org/posterior/reference/ess_tail.html)\n",
    "\n",
    "#### Effective sample size\n",
    "\n",
    "$$n_{\\text{eff}} = \\frac{m}{\\sum_{k=-\\infty}^\\infty\\rho_k} = \\frac{m}{1+2\\sum_{k=1}^\\infty\\rho_k} \\quad \\text{ for order $k$ autocorrelations } \\quad \\rho_k $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "K = 30\n",
    "autocorrelations = np.ones((2,int(m/2)))\n",
    "for c in range(C):\n",
    "    for t_plus_k in range(1, int(m/2)):\n",
    "        autocorrelations[c,t_plus_k] = \\\n",
    "        np.corrcoef(theta[c,:-t_plus_k], \n",
    "                    theta[c,t_plus_k:])[0,1]\n",
    "\n",
    "for c in range(C):\n",
    "    plt.plot(autocorrelations[c,:K], label=\"Chain \"+str(c)) \n",
    "\n",
    "# effective sample size\n",
    "approximation_stops=[3,4]\n",
    "approximation_stops,\n",
    "m / (1 + 2*autocorrelations[0,1:approximation_stops[0]].sum())+\\\n",
    "m / (1 + 2*autocorrelations[1,1:approximation_stops[1]].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfba2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelations[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "K = 30\n",
    "autocorrelations = np.ones((2,int(m/2)))\n",
    "for c in range(C):\n",
    "    for t_plus_k in range(1, int(m/2)):\n",
    "        autocorrelations[c,t_plus_k] = \\\n",
    "        np.corrcoef(tau[c,:-t_plus_k], \n",
    "                    tau[c,t_plus_k:])[0,1]\n",
    "\n",
    "for c in range(C):\n",
    "    plt.plot(autocorrelations[c,:K], label=\"Chain \"+str(c)) \n",
    "\n",
    "# effective sample size\n",
    "approximation_stops=[5,7]\n",
    "approximation_stops,\n",
    "m / (1 + 2*autocorrelations[0,1:approximation_stops[0]].sum())+\\\n",
    "m / (1 + 2*autocorrelations[1,1:approximation_stops[1]].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelations[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6808dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, round_to=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd50ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].plot(theta.ravel()[:-1], theta.ravel()[1:], '.', alpha=0.25)\n",
    "ax[1].plot(tau.ravel()[:-1], tau.ravel()[1:], '.', alpha=0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2f9ad",
   "metadata": {},
   "source": [
    "## Part C: R-hat and \"energy\"\n",
    "\n",
    "A lack of insufficient \"mixing\" (agreement) between chains is diagnosed by comparing within and between chain variability. This is done by **checking if the split-$\\hat R$ statistic is greater than** $\\mathbf{1.05}$. is deemed sufficient when . This is suggestive (but not proof) that the the **Markov chains** have converged to their **stationary distributions**.\n",
    "\n",
    "> Thus far above we have avoided the notion of \"split\" chains. Split chains must be considered to ensure that a \"drifting chain\" does not accidentally pass the $\\hat R$ check. Thus the split-$\\hat R$ statistic.\n",
    "\n",
    "\n",
    "$\\Large \\text{Split-}\\hat R  = \\sqrt{\\frac{\\frac{N-1}{N}W +  \\overbrace{\\frac{1}{M-1}\\sum_{m=1}^M (\\overline{\\theta^{(m,\\cdot)}} - \\overline{\\theta^{(\\cdot,\\cdot)}})^2}^{\\text{between chain variance}} }{\\underbrace{\\frac{1}{M}\\sum_{m=1}^M \\frac{1}{N-1}\\sum_{n=1}^N (\\theta^{(m,n)} - \\overline{\\theta^{(m,\\cdot)}})^2}_{\\text{$W$: within chain variance}}} } $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, round_to=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a2716",
   "metadata": {},
   "source": [
    "### Energy\n",
    "\n",
    "Another diagnostic that sometimes applies is based on the so-called [energy](https://discourse.mc-stan.org/t/help-understanding-bfmi-interpreting-bfmi-1/28554). The exact meaning of \"energy\" will be discussed next class but for now suffice it to say that when the \"Energy transition\" fails to dominate the \"Marginal energy\" the sampler is experiencing a computational bottleneck.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89548968",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_energy(idata);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb985d",
   "metadata": {},
   "source": [
    "## Part D: Samplers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc.sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conjugate_normal_gamma:\n",
    "    HMC = pymc.HamiltonianMC()\n",
    "    idata_HMC = pymc.sample(chains=4, step=HMC)\n",
    "    \n",
    "display(az.summary(idata_HMC, round_to=2))\n",
    "az.plot_trace(idata_HMC)\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3222eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta rejection rates\n",
    "(idata_HMC.posterior.theta.values[:,:-1]==idata_HMC.posterior.theta.values[:,1:]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau rejection rates\n",
    "(idata_HMC.posterior.tau.values[:,:-1]==idata_HMC.posterior.tau.values[:,1:]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].plot(idata_HMC.posterior.theta.values.ravel()[:-1], \n",
    "           idata_HMC.posterior.theta.values.ravel()[1:], '.', alpha=0.25)\n",
    "ax[1].plot(idata_HMC.posterior.tau.values.ravel()[:-1], \n",
    "           idata_HMC.posterior.tau.values.ravel()[1:], '.', alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87933d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conjugate_normal_gamma:\n",
    "    idata = pymc.sample(chains=4, target_accept=0.9)\n",
    "    \n",
    "display(az.summary(idata, round_to=2))\n",
    "az.plot_trace(idata)\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b6cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "display(pd.DataFrame(idata.sample_stats.acceptance_rate))\n",
    "# rejection rates\n",
    "1-idata.sample_stats.acceptance_rate.values.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d430875",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].plot(idata.posterior.theta.values.ravel()[:-1], \n",
    "           idata.posterior.theta.values.ravel()[1:], '.', alpha=0.25)\n",
    "ax[1].plot(idata.posterior.tau.values.ravel()[:-1], \n",
    "           idata.posterior.tau.values.ravel()[1:], '.', alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8db5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conjugate_normal_gamma:\n",
    "    sampler = pymc.Slice()\n",
    "    idata_slice = pymc.sample(step=sampler)\n",
    "\n",
    "display(az.summary(idata_slice, round_to=2))\n",
    "az.plot_trace(idata_slice)\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd6094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta rejection rates\n",
    "(idata_slice.posterior.theta.values[:,:-1]==idata_slice.posterior.theta.values[:,1:]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b64e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau rejection rates\n",
    "(idata_slice.posterior.tau.values[:,:-1]==idata_slice.posterior.tau.values[:,1:]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe14d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].plot(idata_slice.posterior.theta.values.ravel()[:-1], \n",
    "           idata_slice.posterior.theta.values.ravel()[1:], '.', alpha=0.25)\n",
    "ax[1].plot(idata_slice.posterior.tau.values.ravel()[:-1], \n",
    "           idata_slice.posterior.tau.values.ravel()[1:], '.', alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conjugate_normal_gamma:\n",
    "    MHv1 = pymc.Metropolis(S=np.ones(1), scaling=1, tune=False)\n",
    "    idata_MHv1 = pymc.sample(draws=1000, tune=0, chains=4, step=MHv1)\n",
    "\n",
    "display(az.summary(idata_MHv1, round_to=2))\n",
    "az.plot_trace(idata_MHv1)\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta rejection rates\n",
    "(idata_MHv1.posterior.theta.values[:,:-1]==idata_MHv1.posterior.theta.values[:,1:]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa353f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau rejection rates\n",
    "(idata_MHv1.posterior.tau.values[:,:-1]==idata_MHv1.posterior.tau.values[:,1:]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].plot(idata_MHv1.posterior.theta.values.ravel()[:-1], \n",
    "           idata_MHv1.posterior.theta.values.ravel()[1:], '.', alpha=0.25)\n",
    "ax[1].plot(idata_MHv1.posterior.tau.values.ravel()[:-1], \n",
    "           idata_MHv1.posterior.tau.values.ravel()[1:], '.', alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a89e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conjugate_normal_gamma:\n",
    "    MHv2 = pymc.Metropolis(S=np.ones(1), scaling=0.1, tune=False)\n",
    "    idata_MHv2 = pymc.sample(draws=1000, tune=0, chains=4, step=MHv2)\n",
    "\n",
    "display(az.summary(idata_MHv2, round_to=2))\n",
    "az.plot_trace(idata_MHv2)\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626112f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta rejection rates\n",
    "(idata_MHv2.posterior.theta.values[:,:-1]==idata_MHv2.posterior.theta.values[:,1:]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176fe6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau rejection rates\n",
    "(idata_MHv2.posterior.tau.values[:,:-1]==idata_MHv2.posterior.tau.values[:,1:]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].plot(idata_MHv2.posterior.theta.values.ravel()[:-1], \n",
    "           idata_MHv2.posterior.theta.values.ravel()[1:], '.', alpha=0.25)\n",
    "ax[1].plot(idata_MHv2.posterior.tau.values.ravel()[:-1], \n",
    "           idata_MHv2.posterior.tau.values.ravel()[1:], '.', alpha=0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf412f",
   "metadata": {},
   "source": [
    "## Week 5 Homework\n",
    "\n",
    "---\n",
    "\n",
    "### Q1: Questions about PyMC...\n",
    "\n",
    "Complete this formatted markdown listing of the contents of \"PyMC Example Gallery\". *Include links and your favorite image (right click and \"copy image address\") from each page.*\n",
    "\n",
    "\n",
    "#### Introductory\n",
    "\n",
    "- [General Overview](https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/pymc_overview.html)\n",
    "- [Simple Linear Regression](https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/GLM_linear.html)\n",
    "- [General API quickstart](https://www.pymc.io/projects/examples/en/latest/introductory/api_quickstart.html)\n",
    "\n",
    "| | | |\n",
    "|-|-|-|\n",
    "|![](https://www.pymc.io/projects/docs/en/stable/_images/ac30f30b2297ec4f2bb798b4f28d2cbba2d0502dbaae4a5f78fdd5cccacda517.svg)|<img src=\"https://www.pymc.io/projects/docs/en/stable/_images/a8276d1222c43c061dbfff6fa3ff3af15b86038fd7d1e204c429ae3714ea1a20.png\"  width=\"500\"/>|![](https://www.pymc.io/projects/examples/en/latest/_images/434538d8660bf2399ebf9df11cbd2b7cec62d8abafc588da625315074b628118.png)|\n",
    "\n",
    "#### Library Fundamentals\n",
    "\n",
    "- Distribution Dimensionality\n",
    "- PyMC and PyTensor\n",
    "- Using Data Containers\n",
    "\n",
    "| | | |\n",
    "|-|-|-|\n",
    "|1|2|3|\n",
    "\n",
    "\n",
    "#### Etc.\n",
    "\n",
    "- 1.\n",
    "- 2.\n",
    "- 3.\n",
    "- 4.\n",
    "- 5.\n",
    "- 6.\n",
    "- 7.\n",
    "- 8.\n",
    "- 9.\n",
    "- 10.\n",
    "- 11.\n",
    "- 12.\n",
    "- 13.\n",
    "\n",
    "\n",
    "| | | | |\n",
    "|-|-|-|-|\n",
    "|1|2|3|4|\n",
    "|5|6|7|8|\n",
    "|9|10|11|12|\n",
    "\n",
    "Etc.\n",
    "\n",
    "\n",
    "### Q2: Continue \"Q2\" of the previous weeks 3 and 4\n",
    "\n",
    "1. *Use PyMC to provide Bayesian inference for the paramaters associated with a sample of normal data where your prior for theta is a normal distribution and your prior for $\\tau$ is a gamma distribution. Provide diagnostic assessments of the performance of your algorithm.*\n",
    "\n",
    "2. *Use PyMC to provide Bayesian inference for the paramaters associated with a sample of normal data where your prior for theta is a non normal distribution and your prior for $\\tau$ is a non-gamma distribution. Provide diagnostic assessments of the performance of your algorithm.*\n",
    "\n",
    "3. *Use PyMC to provide Bayesian inference for the paramaters associated with a sample of normal data where your prior for theta is a yet another different again non normal distribution and your prior for $\\tau$ is a yet another different again non-gamma distribution. Provide diagnostic assessments of the performance of your algorithm.*\n",
    "\n",
    "### Q3: Slice Sampling\n",
    "\n",
    "*First explain how the Markov algorithm of slice sampling as given below works. Then explain the steps by which slice sampling could be used in place of a Metropolis-Hasting step in a Metropolis within Gibbs algorithm where the full conditionals are only known up to a normalizing constant. In your explanation clarify what the curve that we're sampling beneath is, and what the initial value and steps are to create the draw for Gibbs sampling.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_f_at_y(f, x, y, x_grid=np.linspace(0,1,51)):\n",
    "    \n",
    "    # find interval of grid points where f(x_grid) > y \n",
    "    # then extend the enterval so endpoints f(a)<y and f(b)<y \n",
    "    x_grid_delta = x_grid[1]-x_grid[0]\n",
    "    a,b = x_grid[f(x_grid)>y][[0,-1]]+[-x_grid_delta,x_grid_delta]\n",
    "    # a,b = x_grid[0,-1]  # make the interval all of x_grid\n",
    "    \n",
    "    x_ = a + stats.uniform().rvs()*(b-a)    \n",
    "    if f(x_)>y:\n",
    "        return x_,1  # in 1 try if f(x_)>y and \"x_ is under f\" \n",
    "    elif x_ < x:  # or if \"x_ was above f on the left side of the interval\" \n",
    "        x_l,x_r = x_,b\n",
    "    else:\n",
    "        x_l,x_r = a,x_  # or if \"x_ was above f on the right side of the interval\"\n",
    "    return slice_f_at_y_(f, x, y, x_l, x_r, tot = 2)  # try again with a reduced interval\n",
    "\n",
    "def slice_f_at_y_(f, x, y, x_l=0, x_r=1, tot=1):\n",
    "    \n",
    "    x_ = x_l + stats.uniform().rvs()*(x_r-x_l)\n",
    "    \n",
    "    if f(x_)>y:\n",
    "        return x_,tot\n",
    "    elif x_ < x:\n",
    "        x_l = x_\n",
    "    else:\n",
    "        x_r = x_\n",
    "    return slice_f_at_y_(f, x, y, x_l, x_r, tot = tot+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d820203",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = np.linspace(0,1,1000)\n",
    "f = lambda x: stats.beta(1.5,3).pdf(x)\n",
    "plt.plot(x_grid, f(x_grid))\n",
    "    \n",
    "m = 1000\n",
    "x = np.zeros([m+1,3])\n",
    "x[:2,0] = 0.25\n",
    "\n",
    "plot_trace = 10\n",
    "for t in range(1,m):\n",
    "    \n",
    "    x[t,1] = stats.uniform().rvs()*f(x[t,0])\n",
    "    if t < plot_trace:\n",
    "        plt.plot([x[t,0]]*2, [x[t-1,1],x[t,1]], 'k')\n",
    "    \n",
    "    x[t+1,0],x[t+1,2] = slice_f_at_y(f, x[t,0], x[t,1])\n",
    "    if t < plot_trace:\n",
    "        if t==1:\n",
    "            plt.plot([x[t,0], x[t+1,0]], [x[t,1]]*2, 'k--', label=str(plot_trace)+ \" iterations\")\n",
    "        plt.plot([x[t,0], x[t+1,0]], [x[t,1]]*2, 'k--')\n",
    "    \n",
    "plt.hist(x[:,0], density=True, label=str(m)+\" iterations\\n x values only\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f057239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
